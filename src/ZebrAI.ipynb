{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 764,
   "id": "a0e9a5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['image.interpolation'] = 'none'\n",
    "import numpy as np\n",
    "import cv2\n",
    "import math\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "import itertools\n",
    "import random\n",
    "from sklearn.linear_model import RANSACRegressor, LinearRegression\n",
    "import torch\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import seaborn as sns\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "import random\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 765,
   "id": "ed28101a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image(image_path, model):\n",
    "    img = cv2.imread(image_path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    results = model(img)\n",
    "    detections = results.pandas().xyxy[0]\n",
    "    results.render()\n",
    "\n",
    "    traffic_lights = []\n",
    "    zebra_crops = []\n",
    "\n",
    "    for _, row in detections.iterrows():\n",
    "        class_name = row['name']\n",
    "        xmin, ymin, xmax, ymax = map(int, [row['xmin'], row['ymin'], row['xmax'], row['ymax']])\n",
    "        coords = (xmin, ymin, xmax, ymax)\n",
    "        confidence = round(float(row['confidence']), 2)\n",
    "\n",
    "        if class_name == 'Zebra_Cross':\n",
    "            zebra_crops.append((coords, confidence))\n",
    "        elif class_name == 'G_Signal':\n",
    "            traffic_lights.append({'coords': coords, 'confidence': confidence, 'color': 'green'})\n",
    "        elif class_name == 'R_Signal':\n",
    "            traffic_lights.append({'coords': coords, 'confidence': confidence, 'color': 'red'})\n",
    "\n",
    "    return results, traffic_lights, zebra_crops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 766,
   "id": "cc17fc7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_results(row, ptl_list, zebra_crops, zebra, red, green):\n",
    "    if row['zebra'] == 1:  # Ground truth: Zebra crossing present\n",
    "        if zebra_crops:  # Prediction: Zebra crossing detected\n",
    "            zebra[0] += 1  # TP\n",
    "        else:  # Prediction: Zebra crossing not detected\n",
    "            zebra[2] += 1  # FN\n",
    "    else:  # Ground truth: No zebra crossing\n",
    "        if zebra_crops:  # Prediction: Zebra crossing detected\n",
    "            zebra[1] += 1  # FP\n",
    "        else:  # Prediction: Zebra crossing not detected\n",
    "            zebra[3] += 1  # TN\n",
    "\n",
    "    if ptl_list:  # Traffic light(s) detected\n",
    "        if row['mode'] in [0, 3]:  # Ground truth: Red light should be present\n",
    "            if ptl_list[0]['color'] == 'red':\n",
    "                red[0] += 1  # TP\n",
    "            else:\n",
    "                red[2] += 1  # FN\n",
    "        else:  # Ground truth: Red light should NOT be present\n",
    "            if ptl_list[0]['color'] == 'red':\n",
    "                red[1] += 1  # FP\n",
    "            else:\n",
    "                red[3] += 1  # TN\n",
    "\n",
    "        if row['mode'] in [1, 2]:  # Ground truth: Green light should be present\n",
    "            if ptl_list[0]['color'] == 'green':\n",
    "                green[0] += 1  # TP\n",
    "            else:\n",
    "                green[2] += 1  # FN\n",
    "        else:  # Ground truth: Green light should NOT be present\n",
    "            if ptl_list[0]['color'] == 'green':\n",
    "                green[1] += 1  # FP\n",
    "            else:\n",
    "                green[3] += 1  # TN\n",
    "    else:  # No traffic lights detected\n",
    "        if row['mode'] in [0, 3]:  # Ground truth: Red light should be present\n",
    "            red[1] += 1  # FP (Model didn't detect it)\n",
    "        else:  # Ground truth: Red light should NOT be present\n",
    "            red[3] += 1  # TN (Model correctly didn't detect it)\n",
    "\n",
    "        if row['mode'] in [1, 2]:  # Ground truth: Green light should be present\n",
    "            green[1] += 1  # FP (Model didn't detect it)\n",
    "        else:  # Ground truth: Green light should NOT be present\n",
    "            green[3] += 1  # TN (Model correctly didn't detect it)\n",
    "\n",
    "    return zebra, red, green"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 767,
   "id": "b88787f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(type):\n",
    "    total = sum(type)\n",
    "    tp = type[0]\n",
    "    fp = type[1]\n",
    "    fn = type[2]\n",
    "    tn = type[3]\n",
    "\n",
    "    accuracy = (tp + tn) / total if total > 0 else 0\n",
    "\n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "\n",
    "    f1_score = (2 * precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "\n",
    "    return {\n",
    "        'accuracy': round(accuracy, 2),\n",
    "        'precision': round(precision, 2),\n",
    "        'recall': round(recall, 2),\n",
    "        'f1_score': round(f1_score, 2)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 768,
   "id": "88df9425",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_confusion_matrices_with_metrics(zebra, red, green, zebra_metrics, red_metrics, green_metrics, filename=\"Matriu de confusió.png\"):\n",
    "    clases = ['Pas de zebra', 'Semàfor vermell', 'Semàfor verd']\n",
    "    datos = [zebra, red, green]\n",
    "    all_metrics = [zebra_metrics, red_metrics, green_metrics]\n",
    "\n",
    "    fig, axs = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "    for ax, clase, (tp, fp, fn, tn), metrics in zip(axs, clases, datos, all_metrics):\n",
    "        matrix = np.array([[tp, fn],\n",
    "                           [fp, tn]])\n",
    "\n",
    "        sns.heatmap(matrix, annot=True, fmt=\"d\", cmap=\"Reds\", cbar=False, ax=ax, xticklabels=['Positiu', 'Negatiu'], yticklabels=['Positiu', 'Negatiu'], annot_kws={\"size\": 15})\n",
    "\n",
    "        ax.set_title(f'{clase}')\n",
    "        ax.set_xlabel('Predicció')\n",
    "        ax.set_ylabel('Real')\n",
    "\n",
    "        metrics_text = f\"Accuracy: {metrics['accuracy']}\\nPrecision: {metrics['precision']}\\nRecall: {metrics['recall']}\\nF1: {metrics['f1_score']}\"\n",
    "        ax.text(0.05, -0.3, metrics_text, size=18, ha='left', va='top', transform=ax.transAxes) \n",
    "\n",
    "    plt.tight_layout(rect=[0, 0.03, 1, 0.95]) \n",
    "    plt.savefig(filename)\n",
    "    plt.close(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 769,
   "id": "1e07125d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_images(imgs, titles, width=5):\n",
    "    n = len(imgs)\n",
    "    rows = math.ceil(n / 3)\n",
    "    cols = n // rows\n",
    "    h, w = imgs[0].shape[:2]\n",
    "    fig, axs = plt.subplots(rows, cols, figsize=(width * cols, width * h / w * rows))\n",
    "    axs = axs.flatten()\n",
    "    for i in range(rows * cols):\n",
    "        if i < n:\n",
    "            img = imgs[i]\n",
    "            axs[i].imshow(img, cmap='gray' if img.ndim == 2 else None)\n",
    "            axs[i].set_title(titles[i])\n",
    "        axs[i].axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def to_float(img):\n",
    "    img = img.astype(np.float64)\n",
    "    return (img - np.min(img)) / (np.max(img) - np.min(img))\n",
    "\n",
    "def to_uint8(img):\n",
    "    norm = (img - np.min(img)) / (np.max(img) - np.min(img))\n",
    "    return np.round(norm * 255).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 770,
   "id": "943881eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def noise_filter(src, option='median', med_k=5, gauss_sigma=1.5, bilat_d=6, bilat_sigmaColor=75, bilat_sigmaSpace=75, morph_kernel=5, **kwargs):\n",
    "    if option == 'median':\n",
    "        return cv2.medianBlur(src, med_k)\n",
    "    elif option == 'gaussian':\n",
    "        ksize = round(6 * gauss_sigma + 1)\n",
    "        ksize += 1 - (ksize % 2)\n",
    "        return cv2.GaussianBlur(src, (ksize, ksize), gauss_sigma)\n",
    "    elif option == 'bilateral':\n",
    "        return cv2.bilateralFilter(src, d=bilat_d, sigmaColor=bilat_sigmaColor, sigmaSpace=bilat_sigmaSpace)\n",
    "    elif option == 'morph_max':\n",
    "        kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (morph_kernel, morph_kernel))\n",
    "        return cv2.morphologyEx(src, cv2.MORPH_DILATE, kernel)\n",
    "    else:\n",
    "        raise ValueError(f\"Invalid filter option: {option}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 771,
   "id": "fe520d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_threshold(src, option='mixture', **kwargs):\n",
    "    if option == 'otsu':\n",
    "        thr, _ = cv2.threshold(src, 0, 256, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "        return thr\n",
    "    elif option == 'mixture':\n",
    "        hist, bins = np.histogram(src, bins=256, range=(0, 256))\n",
    "        sample = cv2.resize(src, (14, 14), interpolation=cv2.INTER_CUBIC).reshape(-1, 1)\n",
    "        gmm = GaussianMixture(n_components=2, covariance_type='full', random_state=42)\n",
    "        gmm.fit(sample)\n",
    "        means = gmm.means_.flatten()\n",
    "        m1, m2 = np.sort(means)\n",
    "        hist_smooth = gaussian_filter1d(hist, sigma=2)\n",
    "        bin_centers = (bins[:-1] + bins[1:]) / 2\n",
    "        mask = (bin_centers > m1) & (bin_centers < m2)\n",
    "        thr = bin_centers[mask][np.argmin(hist_smooth[mask])]\n",
    "        return thr\n",
    "    else:\n",
    "        raise ValueError(f\"Invalid thresholding option: {option}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 772,
   "id": "a0179d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_edges(src, option=\"laplacian\", canny_thr1=50, canny_thr2=150, **kwargs):\n",
    "    if option == \"canny\":\n",
    "        return cv2.Canny(src, canny_thr1, canny_thr2, apertureSize=3)\n",
    "    elif option == \"laplacian\":\n",
    "        src_blur = cv2.GaussianBlur(src, (5,5), 0)\n",
    "        lap = cv2.Laplacian(src_blur, ddepth=cv2.CV_64F)\n",
    "        z1 = np.roll(lap, 1, axis=0) * np.roll(lap, -1, axis=0)\n",
    "        z2 = np.roll(lap, 1, axis=1) * np.roll(lap, -1, axis=1)\n",
    "        return np.logical_or(z1 < 0, z2 < 0).astype(np.uint8) * 255\n",
    "    else:\n",
    "        raise ValueError(f\"Invalid edges option: {option}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 773,
   "id": "070e6d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_intersection(l1, l2):\n",
    "    rho1, theta1 = l1\n",
    "    rho2, theta2 = l2\n",
    "    A = np.array([\n",
    "        [np.cos(theta1), np.sin(theta1)],\n",
    "        [np.cos(theta2), np.sin(theta2)]\n",
    "    ])\n",
    "    b = np.array([[rho1], [rho2]])\n",
    "    if np.abs(np.linalg.det(A)) < 1e-6:\n",
    "        return None\n",
    "    intersection = np.linalg.solve(A, b)\n",
    "    return intersection.flatten()\n",
    "\n",
    "def point_line_distance(x0, y0, rho, theta):\n",
    "    return abs(x0 * np.cos(theta) + y0 * np.sin(theta) - rho)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 774,
   "id": "5bd0914e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_filtered_lines(edges, high_thr=240, low_thr=150, centroids_sep=100, line_dist_thr=30, **kwargs):\n",
    "    few_raw = cv2.HoughLines(edges, 1, np.pi/180, threshold=high_thr)\n",
    "    raw = cv2.HoughLines(edges, 1, np.pi/180, threshold=low_thr)\n",
    "    if few_raw is None or raw is None:\n",
    "        return []\n",
    "    few_lines = few_raw[:, 0, :]\n",
    "    lines = raw[:, 0, :]\n",
    "\n",
    "    intersections = []\n",
    "    for l1, l2 in itertools.combinations(few_lines, 2):\n",
    "        pt = get_intersection(l1, l2)\n",
    "        if pt is not None and np.all(np.isfinite(pt)):\n",
    "            intersections.append(pt)\n",
    "    if not intersections:\n",
    "        return few_lines\n",
    "    intersections = np.array(intersections)\n",
    "\n",
    "    clustering = DBSCAN(eps=40, min_samples=5).fit(intersections)\n",
    "    labels = clustering.labels_\n",
    "    if np.sum(labels != -1) == 0:\n",
    "        return few_lines\n",
    "\n",
    "    unique_labels = np.unique(labels[labels != -1])\n",
    "    cluster_sizes = np.array([np.sum(labels == k) for k in unique_labels])\n",
    "    centroids = np.stack([intersections[labels == k].mean(axis=0) for k in unique_labels])\n",
    "    centroids = centroids[np.argsort(cluster_sizes)[::-1]]\n",
    "\n",
    "    points = []\n",
    "    for centroid in centroids:\n",
    "        if all(centroid[0]-p[0] > centroids_sep and centroid[1]-p[1] > centroids_sep for p in points):\n",
    "            points.append(centroid)\n",
    "    points = np.array(points)\n",
    "\n",
    "    filtered_lines = []\n",
    "    for rho, theta in lines:\n",
    "        for x, y in points:\n",
    "            if point_line_distance(x, y, rho, theta) < line_dist_thr:\n",
    "                filtered_lines.append([rho, theta])\n",
    "                break\n",
    "    filtered_lines = np.array(filtered_lines)\n",
    "\n",
    "    return filtered_lines\n",
    "\n",
    "def remove_duplicate_lines(lines, shape):\n",
    "    if len(lines) == 0:\n",
    "        return np.array([])\n",
    "\n",
    "    lines = np.array(lines)\n",
    "    h, w = shape[:2]\n",
    "    d = np.hypot(h, w)\n",
    "    theta_mean = np.mean(lines[:, 1])\n",
    "    keep = np.ones(len(lines), dtype=bool)\n",
    "\n",
    "    def get_line_points(rho, theta):\n",
    "        a = np.cos(theta)\n",
    "        b = np.sin(theta)\n",
    "        x0 = a * rho\n",
    "        y0 = b * rho\n",
    "        pt1 = np.array([x0 + d * -b, y0 + d * a])\n",
    "        pt2 = np.array([x0 - d * -b, y0 - d * a])\n",
    "        return pt1, pt2\n",
    "\n",
    "    def intersection(p1, p2, q1, q2):\n",
    "        A = np.array([[p2[0] - p1[0], q1[0] - q2[0]],\n",
    "                      [p2[1] - p1[1], q1[1] - q2[1]]])\n",
    "        b = np.array([q1[0] - p1[0], q1[1] - p1[1]])\n",
    "        if np.linalg.matrix_rank(A) < 2:\n",
    "            return None\n",
    "        t = np.linalg.solve(A, b)\n",
    "        return p1 + t[0] * (p2 - p1)\n",
    "\n",
    "    for i in range(len(lines)):\n",
    "        if not keep[i]:\n",
    "            continue\n",
    "        rho1, theta1 = lines[i]\n",
    "        p1, p2 = get_line_points(rho1, theta1)\n",
    "        for j in range(i + 1, len(lines)):\n",
    "            if not keep[j]:\n",
    "                continue\n",
    "            rho2, theta2 = lines[j]\n",
    "            q1, q2 = get_line_points(rho2, theta2)\n",
    "            inter = intersection(p1, p2, q1, q2)\n",
    "            if inter is not None:\n",
    "                x, y = inter\n",
    "                if 0 <= x < w and 0 <= y < h:\n",
    "                    dist_i = abs(theta1 - theta_mean)\n",
    "                    dist_j = abs(theta2 - theta_mean)\n",
    "                    if dist_i > dist_j:\n",
    "                        keep[i] = False\n",
    "                        break\n",
    "                    else:\n",
    "                        keep[j] = False\n",
    "\n",
    "    return lines[keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 775,
   "id": "9142141a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment_from_rho_theta(rho, theta, edge_img, epsilon=1.0):\n",
    "\n",
    "    ys, xs = np.nonzero(edge_img) \n",
    "    pts = np.stack([xs, ys], axis=1).astype(np.float32)\n",
    "\n",
    "    n = np.array([np.cos(theta), np.sin(theta)]) \n",
    "    v = np.array([-np.sin(theta),  np.cos(theta)])\n",
    "    d = np.abs(pts @ n - rho)\n",
    "    on_line = pts[d < epsilon]\n",
    "\n",
    "    if len(on_line) < 2:\n",
    "        return None\n",
    "    \n",
    "    t = on_line @ v\n",
    "    p_min = on_line[np.argmin(t)]\n",
    "    p_max = on_line[np.argmax(t)]\n",
    "    \n",
    "    return tuple(p_min.astype(int)), tuple(p_max.astype(int))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 776,
   "id": "1da4ebda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_near_points(p1, p2, pts, dist):\n",
    "    pts = np.asarray(pts, dtype=float)\n",
    "    p1  = np.asarray(p1,  dtype=float)\n",
    "    p2  = np.asarray(p2,  dtype=float)\n",
    "\n",
    "    v = p2 - p1\n",
    "    norm_v = np.linalg.norm(v)\n",
    "\n",
    "    if norm_v == 0:\n",
    "        raise ValueError(\"p1 y p2 no poden coincidir.\")\n",
    "    dif   = p1 - pts\n",
    "    cross = v[0] * dif[:, 1] - v[1] * dif[:, 0]\n",
    "\n",
    "    dists = np.abs(cross) / norm_v\n",
    "    return np.sum(dists < dist)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 777,
   "id": "8e6909cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_line_ransac(points, ransac_dist=20, ransac_n_iter=100, **kwargs):\n",
    "    n_lines = len(points)\n",
    "    best_p=(0,0)\n",
    "    best_k=0\n",
    "    if points is not None:\n",
    "            for i in range(ransac_n_iter):\n",
    "                p1 = points[random.randint(0, n_lines-1)]\n",
    "                p2 = points[random.randint(0, n_lines-1)]\n",
    "                while np.all(p1 == p2):\n",
    "                    p2 = points[random.randint(0, n_lines-1)]\n",
    "                k = count_near_points(p1,p2, points, ransac_dist)\n",
    "                if k > best_k:\n",
    "                    best_k = k\n",
    "                    best_p = (p1, p2)\n",
    "    return best_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 778,
   "id": "87f022b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def intersect_polar_with_segment(rho, theta, segment, eps=1e-6):\n",
    "    (x1, y1), (x2, y2) = segment\n",
    "    dx, dy = x2 - x1, y2 - y1\n",
    "    denom = dx*np.cos(theta) + dy*np.sin(theta)\n",
    "    if abs(denom) < eps:\n",
    "        return None\n",
    "    t = (rho - (x1*np.cos(theta) + y1*np.sin(theta))) / denom\n",
    "    x = x1 + t*dx\n",
    "    y = y1 + t*dy\n",
    "    return (int(round(x)), int(round(y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 779,
   "id": "f3ffbb93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_limits(representative_lines, edges, ransac_dist=20, ransac_n_iter=100, **kwargs):\n",
    "    lista_extremos = []\n",
    "    for (rho, theta) in representative_lines:\n",
    "        extremos = segment_from_rho_theta(rho, theta, edges, epsilon=1.5)\n",
    "        if extremos is not None:\n",
    "            lista_extremos.append(extremos)\n",
    "    lista_extremos = np.array(lista_extremos)\n",
    "\n",
    "    # Retornem els límits de la imatge en cas de no trobar múltiples extrems\n",
    "    if len(lista_extremos) <= 1:\n",
    "        h, w = edges.shape\n",
    "        return ((0,0), (0,h)), ((w,0), (w,h))\n",
    "\n",
    "    izq = lista_extremos[:, 0]\n",
    "    der = lista_extremos[:, 1]\n",
    "    p_izq=get_line_ransac(izq, ransac_dist, ransac_n_iter)\n",
    "    p_der=get_line_ransac(der, ransac_dist, ransac_n_iter)\n",
    "\n",
    "    return p_izq, p_der"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 780,
   "id": "77c2f44c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mid_points(lines, p_izq, p_der, shape):\n",
    "\n",
    "    lista_midpoints = []\n",
    "    h, w = shape\n",
    "\n",
    "    for rho, theta in lines:\n",
    "        sin_t, cos_t = np.sin(theta), np.cos(theta)\n",
    "        if abs(sin_t) < 1e-6:\n",
    "            continue\n",
    "        pi = intersect_polar_with_segment(rho, theta, p_izq)\n",
    "        pd = intersect_polar_with_segment(rho, theta, p_der)\n",
    "\n",
    "        # Calcul i filtrat de interseccions\n",
    "        border = []\n",
    "        y0 = (rho - 0*cos_t)/sin_t\n",
    "        yw = (rho - w*cos_t)/sin_t\n",
    "        if 0 <= y0 <= h: border.append((0, int(round(y0))))\n",
    "        if 0 <= yw <= h: border.append((w, int(round(yw))))\n",
    "        x0 = (rho - 0*sin_t)/cos_t if abs(cos_t)>1e-6 else None\n",
    "        xh = (rho - h*sin_t)/cos_t if abs(cos_t)>1e-6 else None\n",
    "        if x0 is not None and 0 <= x0 <= w: border.append((int(round(x0)), 0))\n",
    "        if xh is not None and 0 <= xh <= w: border.append((int(round(xh)), h))\n",
    "        if len(border) < 2:\n",
    "            continue\n",
    "        \n",
    "        border = sorted(border, key=lambda p: p[0])\n",
    "        start_border, end_border = border[0], border[-1]\n",
    "\n",
    "        # Seleccio de punts: interseccions si existeixen, si no, els extrems de la imatge\n",
    "        start = pi if pi is not None else start_border\n",
    "        end   = pd if pd is not None else end_border\n",
    "\n",
    "        # Calcul de punt mitjà\n",
    "        mx = int(round((start[0] + end[0]) / 2))\n",
    "        my = int(round((start[1] + end[1]) / 2))\n",
    "        lista_midpoints.append((mx, my))\n",
    "\n",
    "    return lista_midpoints\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 781,
   "id": "afd64fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_angle(midpoints, shape):\n",
    "    h, w = shape\n",
    "    pts = np.array(midpoints)\n",
    "    xs, ys = pts[:,0], pts[:,1]\n",
    "    X = xs.reshape(-1,1)\n",
    "    y = ys\n",
    "\n",
    "    ransac = RANSACRegressor(LinearRegression(), \n",
    "                            residual_threshold = w * 0.005,\n",
    "                            max_trials=100, random_state=42)\n",
    "    ransac.fit(X, y)\n",
    "\n",
    "    m = ransac.estimator_.coef_[0]\n",
    "\n",
    "    angle_rad = np.pi/2 - np.arctan(m)\n",
    "    angle_deg = np.degrees(angle_rad)\n",
    "    \n",
    "    return angle_rad, angle_deg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 782,
   "id": "4596d77a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_init_point(midpoints):\n",
    "    return max(midpoints, key=lambda p: p[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "643fb430",
   "metadata": {},
   "source": [
    "## Evaluació del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 783,
   "id": "b87daf69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_img(img_path, model, **kwargs):\n",
    "    path = '../data'+img_path\n",
    "    results, traffic_lights, zebra_crops = process_image(path, model)\n",
    "    if not zebra_crops:\n",
    "            return pd.Series([img_path, 0, np.nan, np.nan, np.nan, np.nan, np.nan, np.nan])\n",
    "    \n",
    "    try:\n",
    "        mode = 0\n",
    "        if blocked := len(traffic_lights) != 0:\n",
    "            mode = traffic_lights[0][\"color\"] == \"green\"\n",
    "        \n",
    "        (xmin, ymin, xmax, ymax) = zebra_crops[0][0]\n",
    "\n",
    "        img = plt.imread(path)\n",
    "        img = img[ymin:ymax, xmin:xmax]\n",
    "        gray = to_uint8(cv2.cvtColor(img, cv2.COLOR_BGR2GRAY))\n",
    "        cv2.imwrite(\"./actual.jpg\",img)\n",
    "        # print(path)\n",
    "\n",
    "        src = noise_filter(gray, **kwargs)\n",
    "        thr = find_threshold(src, **kwargs)\n",
    "        bw = 255*(src > thr).astype(np.uint8)\n",
    "        edges = get_edges(bw, **kwargs)\n",
    "        filtered_lines = get_filtered_lines(edges, **kwargs)\n",
    "        filtered_lines = remove_duplicate_lines(filtered_lines, gray.shape)\n",
    "        if len(filtered_lines) == 0:\n",
    "             raise Exception(\"No s'han trobat línies\")\n",
    "\n",
    "        p_izq, p_der = get_limits(filtered_lines, edges, **kwargs)\n",
    "        midpoints = get_mid_points(filtered_lines, p_izq, p_der, gray.shape)\n",
    "        angle_rad, angle_deg = get_angle(midpoints, gray.shape)\n",
    "        x, y = get_init_point(midpoints)\n",
    "\n",
    "        return pd.Series([img_path, 1, mode, blocked, x, y, angle_rad, angle_deg])\n",
    "    \n",
    "    except Exception as e:\n",
    "        # print(\"Error:\", e)\n",
    "        print(\"Error: \", e, \" Imatge: \", path, \" Thr: \", thr)\n",
    "        # cv2.imwrite(\"./edges.jpg\", src)\n",
    "        # return pd.Series([img_path, 0, np.nan, np.nan, np.nan, np.nan, np.nan, np.nan])\n",
    "        # raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 784,
   "id": "640b3b65",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOv5  2025-5-16 Python-3.10.11 torch-2.6.0+cpu CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 280 layers, 12315904 parameters, 0 gradients, 16.1 GFLOPs\n",
      "Adding AutoShape... \n",
      "  0%|          | 22/6955 [00:06<30:25,  3.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error:  No s'han trobat línies  Imatge:  ../data/pedestrian-traffic-lights/sam_IMG_1490.jpg  Thr:  36.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 36/6955 [00:10<29:36,  3.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error:  No s'han trobat línies  Imatge:  ../data/pedestrian-traffic-lights/heon_IMG_0987.JPG  Thr:  64.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 66/6955 [00:19<29:37,  3.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error:  No s'han trobat línies  Imatge:  ../data/pedestrian-traffic-lights/heon_IMG_0531.JPG  Thr:  164.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 82/6955 [00:25<34:04,  3.36it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error:  No s'han trobat línies  Imatge:  ../data/pedestrian-traffic-lights/sam_IMG_1624.jpg  Thr:  81.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 103/6955 [00:31<28:36,  3.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error:  `min_samples` may not be larger than number of samples: n_samples = 1.  Imatge:  ../data/pedestrian-traffic-lights/john_IMG_1437.jpg  Thr:  70.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 109/6955 [00:33<29:27,  3.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error:  No s'han trobat línies  Imatge:  ../data/pedestrian-traffic-lights/heon_IMG_1159.JPG  Thr:  64.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 125/6955 [00:37<29:42,  3.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error:  `min_samples` may not be larger than number of samples: n_samples = 1.  Imatge:  ../data/pedestrian-traffic-lights/john_IMG_2747.jpg  Thr:  91.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 150/6955 [00:45<28:11,  4.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error:  No s'han trobat línies  Imatge:  ../data/pedestrian-traffic-lights/heon_IMG_0611.JPG  Thr:  38.5\n",
      "Error:  No s'han trobat línies  Imatge:  ../data/pedestrian-traffic-lights/heon_IMG_0885.JPG  Thr:  64.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 184/6955 [00:54<28:17,  3.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error:  `min_samples` may not be larger than number of samples: n_samples = 1.  Imatge:  ../data/pedestrian-traffic-lights/sam_IMG_2168.JPG  Thr:  180.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 188/6955 [00:55<27:30,  4.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error:  No s'han trobat línies  Imatge:  ../data/pedestrian-traffic-lights/john_IMG_1432.jpg  Thr:  81.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 223/6955 [01:06<29:58,  3.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error:  No s'han trobat línies  Imatge:  ../data/pedestrian-traffic-lights/heon_IMG_0871.JPG  Thr:  64.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▎         | 250/6955 [01:15<28:49,  3.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error:  No s'han trobat línies  Imatge:  ../data/pedestrian-traffic-lights/john_IMG_1504.jpg  Thr:  143.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 267/6955 [01:20<36:27,  3.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error:  No s'han trobat línies  Imatge:  ../data/pedestrian-traffic-lights/heon_IMG_1734.JPG  Thr:  76.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 314/6955 [01:35<27:30,  4.02it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error:  No s'han trobat línies  Imatge:  ../data/pedestrian-traffic-lights/sam_IMG_1700.jpg  Thr:  104.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 336/6955 [01:42<28:26,  3.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error:  No s'han trobat línies  Imatge:  ../data/pedestrian-traffic-lights/john_IMG_1337.jpg  Thr:  204.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 344/6955 [01:44<25:30,  4.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error:  `min_samples` may not be larger than number of samples: n_samples = 1.  Imatge:  ../data/pedestrian-traffic-lights/heon_IMG_1207.JPG  Thr:  70.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 384/6955 [01:56<29:52,  3.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error:  No s'han trobat línies  Imatge:  ../data/pedestrian-traffic-lights/heon_IMG_0519.JPG  Thr:  66.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 422/6955 [02:07<25:59,  4.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error:  `min_samples` may not be larger than number of samples: n_samples = 1.  Imatge:  ../data/pedestrian-traffic-lights/sam_IMG_0860.jpg  Thr:  133.5\n",
      "Error:  No s'han trobat línies  Imatge:  ../data/pedestrian-traffic-lights/heon_IMG_0592.JPG  Thr:  102.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▋         | 445/6955 [02:14<28:26,  3.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error:  No s'han trobat línies  Imatge:  ../data/pedestrian-traffic-lights/sam_IMG_1993.JPG  Thr:  59.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▋         | 449/6955 [02:15<24:53,  4.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error:  No s'han trobat línies  Imatge:  ../data/pedestrian-traffic-lights/heon_IMG_0965.JPG  Thr:  66.5\n",
      "Error:  No s'han trobat línies  Imatge:  ../data/pedestrian-traffic-lights/sam_IMG_1184.jpg  Thr:  173.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 461/6955 [02:18<27:59,  3.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error:  No s'han trobat línies  Imatge:  ../data/pedestrian-traffic-lights/sam_IMG_0686.jpg  Thr:  61.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 484/6955 [02:25<26:23,  4.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error:  No s'han trobat línies  Imatge:  ../data/pedestrian-traffic-lights/sam_IMG_1889.JPG  Thr:  150.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 523/6955 [03:21<28:40,  3.74it/s]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error:  No s'han trobat línies  Imatge:  ../data/pedestrian-traffic-lights/heon_IMG_1543.JPG  Thr:  81.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 536/6955 [03:25<24:16,  4.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error:  No s'han trobat línies  Imatge:  ../data/pedestrian-traffic-lights/john_IMG_1236.jpg  Thr:  125.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 541/6955 [03:26<25:42,  4.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error:  No s'han trobat línies  Imatge:  ../data/pedestrian-traffic-lights/sam_IMG_1813.JPG  Thr:  54.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 545/6955 [03:27<27:27,  3.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error:  No s'han trobat línies  Imatge:  ../data/pedestrian-traffic-lights/heon_IMG_1691.JPG  Thr:  81.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 548/6955 [03:28<24:16,  4.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error:  No s'han trobat línies  Imatge:  ../data/pedestrian-traffic-lights/sam_IMG_1984.JPG  Thr:  83.5\n",
      "Error:  No s'han trobat línies  Imatge:  ../data/pedestrian-traffic-lights/sam_IMG_1489.jpg  Thr:  47.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 582/6955 [03:38<29:22,  3.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error:  `min_samples` may not be larger than number of samples: n_samples = 1.  Imatge:  ../data/pedestrian-traffic-lights/heon_IMG_0890.JPG  Thr:  71.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 591/6955 [03:41<30:45,  3.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error:  No s'han trobat línies  Imatge:  ../data/pedestrian-traffic-lights/sam_IMG_2320.JPG  Thr:  72.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 642/6955 [03:56<29:39,  3.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error:  `min_samples` may not be larger than number of samples: n_samples = 1.  Imatge:  ../data/pedestrian-traffic-lights/heon_IMG_0977.JPG  Thr:  81.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 652/6955 [03:59<29:54,  3.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error:  No s'han trobat línies  Imatge:  ../data/pedestrian-traffic-lights/heon_IMG_1404.JPG  Thr:  76.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 655/6955 [04:00<27:16,  3.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error:  No s'han trobat línies  Imatge:  ../data/pedestrian-traffic-lights/heon_IMG_0971.JPG  Thr:  113.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 660/6955 [04:02<25:51,  4.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error:  No s'han trobat línies  Imatge:  ../data/pedestrian-traffic-lights/sam_IMG_1543.jpg  Thr:  73.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 662/6955 [04:02<23:56,  4.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error:  No s'han trobat línies  Imatge:  ../data/pedestrian-traffic-lights/john_IMG_1452.jpg  Thr:  102.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 703/6955 [04:14<25:59,  4.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error:  `min_samples` may not be larger than number of samples: n_samples = 1.  Imatge:  ../data/pedestrian-traffic-lights/sam_IMG_1322.jpg  Thr:  127.5\n",
      "Error:  No s'han trobat línies  Imatge:  ../data/pedestrian-traffic-lights/john_IMG_0949.jpg  Thr:  73.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 705/6955 [04:14<22:17,  4.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error:  `min_samples` may not be larger than number of samples: n_samples = 1.  Imatge:  ../data/pedestrian-traffic-lights/sam_IMG_1634.jpg  Thr:  80.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 716/6955 [04:17<29:44,  3.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error:  `min_samples` may not be larger than number of samples: n_samples = 1.  Imatge:  ../data/pedestrian-traffic-lights/sam_IMG_1304.jpg  Thr:  186.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 726/6955 [04:20<26:10,  3.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error:  No s'han trobat línies  Imatge:  ../data/pedestrian-traffic-lights/heon_IMG_1447.JPG  Thr:  59.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 735/6955 [04:23<32:54,  3.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error:  No s'han trobat línies  Imatge:  ../data/pedestrian-traffic-lights/sam_IMG_1537.jpg  Thr:  82.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 743/6955 [04:25<29:57,  3.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error:  No s'han trobat línies  Imatge:  ../data/pedestrian-traffic-lights/sam_IMG_2006.JPG  Thr:  79.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 748/6955 [04:27<29:00,  3.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error:  No s'han trobat línies  Imatge:  ../data/pedestrian-traffic-lights/sam_IMG_1498.jpg  Thr:  74.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 753/6955 [04:29<31:42,  3.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error:  No s'han trobat línies  Imatge:  ../data/pedestrian-traffic-lights/john_IMG_1285.jpg  Thr:  124.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 760/6955 [04:31<28:26,  3.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error:  No s'han trobat línies  Imatge:  ../data/pedestrian-traffic-lights/heon_IMG_0751.JPG  Thr:  47.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 762/6955 [04:31<26:17,  3.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error:  No s'han trobat línies  Imatge:  ../data/pedestrian-traffic-lights/sam_IMG_1753.JPG  Thr:  61.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 773/6955 [04:34<25:40,  4.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error:  No s'han trobat línies  Imatge:  ../data/pedestrian-traffic-lights/sam_IMG_1541.jpg  Thr:  70.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 805/6955 [04:44<27:29,  3.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error:  No s'han trobat línies  Imatge:  ../data/pedestrian-traffic-lights/sam_IMG_1926.JPG  Thr:  74.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 807/6955 [04:45<25:47,  3.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error:  No s'han trobat línies  Imatge:  ../data/pedestrian-traffic-lights/sam_IMG_1688.jpg  Thr:  79.5\n",
      "Error:  No s'han trobat línies  Imatge:  ../data/pedestrian-traffic-lights/john_IMG_1496.jpg  Thr:  97.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 830/6955 [04:52<28:08,  3.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error:  No s'han trobat línies  Imatge:  ../data/pedestrian-traffic-lights/john_IMG_1564.jpg  Thr:  88.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 837/6955 [04:54<28:55,  3.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error:  No s'han trobat línies  Imatge:  ../data/pedestrian-traffic-lights/heon_IMG_0870.JPG  Thr:  43.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 844/6955 [04:56<25:33,  3.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error:  `min_samples` may not be larger than number of samples: n_samples = 1.  Imatge:  ../data/pedestrian-traffic-lights/heon_IMG_0571.JPG  Thr:  65.5\n",
      "Error:  No s'han trobat línies  Imatge:  ../data/pedestrian-traffic-lights/heon_IMG_1453.JPG  Thr:  81.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 846/6955 [04:56<22:08,  4.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error:  No s'han trobat línies  Imatge:  ../data/pedestrian-traffic-lights/john_IMG_1784.jpg  Thr:  180.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 851/6955 [04:58<26:34,  3.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error:  No s'han trobat línies  Imatge:  ../data/pedestrian-traffic-lights/john_IMG_1290.jpg  Thr:  104.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 878/6955 [05:06<27:39,  3.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error:  No s'han trobat línies  Imatge:  ../data/pedestrian-traffic-lights/heon_IMG_1142.JPG  Thr:  125.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 882/6955 [05:07<27:20,  3.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error:  No s'han trobat línies  Imatge:  ../data/pedestrian-traffic-lights/john_IMG_1783.jpg  Thr:  184.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 934/6955 [05:23<26:19,  3.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error:  No s'han trobat línies  Imatge:  ../data/pedestrian-traffic-lights/john_IMG_1343.jpg  Thr:  62.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 992/6955 [05:48<23:06,  4.30it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error:  No s'han trobat línies  Imatge:  ../data/pedestrian-traffic-lights/heon_IMG_0633.JPG  Thr:  42.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 996/6955 [05:49<24:06,  4.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error:  No s'han trobat línies  Imatge:  ../data/pedestrian-traffic-lights/heon_IMG_1421.JPG  Thr:  68.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 1007/6955 [05:52<24:00,  4.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error:  No s'han trobat línies  Imatge:  ../data/pedestrian-traffic-lights/heon_IMG_0988.JPG  Thr:  85.5\n",
      "Error:  No s'han trobat línies  Imatge:  ../data/pedestrian-traffic-lights/john_IMG_1241.jpg  Thr:  70.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▍        | 1017/6955 [05:55<23:41,  4.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error:  `min_samples` may not be larger than number of samples: n_samples = 1.  Imatge:  ../data/pedestrian-traffic-lights/john_IMG_1286.jpg  Thr:  85.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 1059/6955 [06:07<27:39,  3.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error:  No s'han trobat línies  Imatge:  ../data/pedestrian-traffic-lights/sam_IMG_2244.JPG  Thr:  71.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 1065/6955 [06:09<27:03,  3.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error:  No s'han trobat línies  Imatge:  ../data/pedestrian-traffic-lights/john_IMG_1276.jpg  Thr:  126.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 1070/6955 [06:11<26:42,  3.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error:  No s'han trobat línies  Imatge:  ../data/pedestrian-traffic-lights/john_IMG_1964.jpg  Thr:  74.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 1121/6955 [06:26<23:34,  4.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error:  No s'han trobat línies  Imatge:  ../data/pedestrian-traffic-lights/john_IMG_1314.jpg  Thr:  157.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 1124/6955 [06:27<25:24,  3.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error:  `min_samples` may not be larger than number of samples: n_samples = 1.  Imatge:  ../data/pedestrian-traffic-lights/heon_IMG_0828.JPG  Thr:  66.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▋        | 1146/6955 [06:33<26:13,  3.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error:  No s'han trobat línies  Imatge:  ../data/pedestrian-traffic-lights/heon_IMG_0722.JPG  Thr:  58.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▋        | 1146/6955 [06:34<33:17,  2.91it/s]\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'thr' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[783], line 21\u001b[0m, in \u001b[0;36mpredict_img\u001b[1;34m(img_path, model, **kwargs)\u001b[0m\n\u001b[0;32m     20\u001b[0m src \u001b[38;5;241m=\u001b[39m noise_filter(gray, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m---> 21\u001b[0m thr \u001b[38;5;241m=\u001b[39m find_threshold(src, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     22\u001b[0m bw \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m255\u001b[39m\u001b[38;5;241m*\u001b[39m(src \u001b[38;5;241m>\u001b[39m thr)\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39muint8)\n",
      "Cell \u001b[1;32mIn[771], line 15\u001b[0m, in \u001b[0;36mfind_threshold\u001b[1;34m(src, option, **kwargs)\u001b[0m\n\u001b[0;32m     14\u001b[0m mask \u001b[38;5;241m=\u001b[39m (bin_centers \u001b[38;5;241m>\u001b[39m m1) \u001b[38;5;241m&\u001b[39m (bin_centers \u001b[38;5;241m<\u001b[39m m2)\n\u001b[1;32m---> 15\u001b[0m thr \u001b[38;5;241m=\u001b[39m bin_centers[mask][\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margmin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhist_smooth\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m]\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m thr\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\numpy\\_core\\fromnumeric.py:1457\u001b[0m, in \u001b[0;36margmin\u001b[1;34m(a, axis, out, keepdims)\u001b[0m\n\u001b[0;32m   1456\u001b[0m kwds \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkeepdims\u001b[39m\u001b[38;5;124m'\u001b[39m: keepdims} \u001b[38;5;28;01mif\u001b[39;00m keepdims \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39m_NoValue \u001b[38;5;28;01melse\u001b[39;00m {}\n\u001b[1;32m-> 1457\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _wrapfunc(a, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124margmin\u001b[39m\u001b[38;5;124m'\u001b[39m, axis\u001b[38;5;241m=\u001b[39maxis, out\u001b[38;5;241m=\u001b[39mout, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\numpy\\_core\\fromnumeric.py:57\u001b[0m, in \u001b[0;36m_wrapfunc\u001b[1;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 57\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m bound(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m     59\u001b[0m     \u001b[38;5;66;03m# A TypeError occurs if the object does have such a method in its\u001b[39;00m\n\u001b[0;32m     60\u001b[0m     \u001b[38;5;66;03m# class, but its signature is not identical to that of NumPy's. This\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     64\u001b[0m     \u001b[38;5;66;03m# Call _wrapit from within the except clause to ensure a potential\u001b[39;00m\n\u001b[0;32m     65\u001b[0m     \u001b[38;5;66;03m# exception has a traceback chain.\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: attempt to get argmin of an empty sequence",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[784], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m tqdm\u001b[38;5;241m.\u001b[39mpandas()\n\u001b[0;32m      5\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../data/dataset.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 7\u001b[0m df_pred \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprogress_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpredict_img\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfile\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tqdm\\std.py:917\u001b[0m, in \u001b[0;36mtqdm.pandas.<locals>.inner_generator.<locals>.inner\u001b[1;34m(df, func, *args, **kwargs)\u001b[0m\n\u001b[0;32m    914\u001b[0m \u001b[38;5;66;03m# Apply the provided function (in **kwargs)\u001b[39;00m\n\u001b[0;32m    915\u001b[0m \u001b[38;5;66;03m# on the df using our wrapper (which provides bar updating)\u001b[39;00m\n\u001b[0;32m    916\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 917\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(df, df_function)(wrapper, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    918\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    919\u001b[0m     t\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\frame.py:10374\u001b[0m, in \u001b[0;36mDataFrame.apply\u001b[1;34m(self, func, axis, raw, result_type, args, by_row, engine, engine_kwargs, **kwargs)\u001b[0m\n\u001b[0;32m  10360\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapply\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m frame_apply\n\u001b[0;32m  10362\u001b[0m op \u001b[38;5;241m=\u001b[39m frame_apply(\n\u001b[0;32m  10363\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m  10364\u001b[0m     func\u001b[38;5;241m=\u001b[39mfunc,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m  10372\u001b[0m     kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[0;32m  10373\u001b[0m )\n\u001b[1;32m> 10374\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapply\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\apply.py:916\u001b[0m, in \u001b[0;36mFrameApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    913\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw:\n\u001b[0;32m    914\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_raw(engine\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine, engine_kwargs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine_kwargs)\n\u001b[1;32m--> 916\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\apply.py:1063\u001b[0m, in \u001b[0;36mFrameApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1061\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mapply_standard\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m   1062\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpython\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m-> 1063\u001b[0m         results, res_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_series_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1064\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1065\u001b[0m         results, res_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_series_numba()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\apply.py:1081\u001b[0m, in \u001b[0;36mFrameApply.apply_series_generator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1078\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m option_context(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode.chained_assignment\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m   1079\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(series_gen):\n\u001b[0;32m   1080\u001b[0m         \u001b[38;5;66;03m# ignore SettingWithCopy here in case the user mutates\u001b[39;00m\n\u001b[1;32m-> 1081\u001b[0m         results[i] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc(v, \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwargs)\n\u001b[0;32m   1082\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(results[i], ABCSeries):\n\u001b[0;32m   1083\u001b[0m             \u001b[38;5;66;03m# If we have a view on v, we need to make a copy because\u001b[39;00m\n\u001b[0;32m   1084\u001b[0m             \u001b[38;5;66;03m#  series_generator will swap out the underlying data\u001b[39;00m\n\u001b[0;32m   1085\u001b[0m             results[i] \u001b[38;5;241m=\u001b[39m results[i]\u001b[38;5;241m.\u001b[39mcopy(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tqdm\\std.py:912\u001b[0m, in \u001b[0;36mtqdm.pandas.<locals>.inner_generator.<locals>.inner.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    906\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    907\u001b[0m     \u001b[38;5;66;03m# update tbar correctly\u001b[39;00m\n\u001b[0;32m    908\u001b[0m     \u001b[38;5;66;03m# it seems `pandas apply` calls `func` twice\u001b[39;00m\n\u001b[0;32m    909\u001b[0m     \u001b[38;5;66;03m# on the first column/row to decide whether it can\u001b[39;00m\n\u001b[0;32m    910\u001b[0m     \u001b[38;5;66;03m# take a fast or slow code path; so stop when t.total==t.n\u001b[39;00m\n\u001b[0;32m    911\u001b[0m     t\u001b[38;5;241m.\u001b[39mupdate(n\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m t\u001b[38;5;241m.\u001b[39mtotal \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mn \u001b[38;5;241m<\u001b[39m t\u001b[38;5;241m.\u001b[39mtotal \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m--> 912\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "Cell \u001b[1;32mIn[784], line 7\u001b[0m, in \u001b[0;36m<lambda>\u001b[1;34m(row)\u001b[0m\n\u001b[0;32m      4\u001b[0m tqdm\u001b[38;5;241m.\u001b[39mpandas()\n\u001b[0;32m      5\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../data/dataset.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 7\u001b[0m df_pred \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mprogress_apply(\u001b[38;5;28;01mlambda\u001b[39;00m row: \u001b[43mpredict_img\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfile\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "Cell \u001b[1;32mIn[783], line 38\u001b[0m, in \u001b[0;36mpredict_img\u001b[1;34m(img_path, model, **kwargs)\u001b[0m\n\u001b[0;32m     34\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m pd\u001b[38;5;241m.\u001b[39mSeries([img_path, \u001b[38;5;241m1\u001b[39m, mode, blocked, x, y, angle_rad, angle_deg])\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     37\u001b[0m     \u001b[38;5;66;03m# print(\"Error:\", e)\u001b[39;00m\n\u001b[1;32m---> 38\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError: \u001b[39m\u001b[38;5;124m\"\u001b[39m, e, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m Imatge: \u001b[39m\u001b[38;5;124m\"\u001b[39m, path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m Thr: \u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[43mthr\u001b[49m)\n",
      "\u001b[1;31mUnboundLocalError\u001b[0m: local variable 'thr' referenced before assignment"
     ]
    }
   ],
   "source": [
    "model = torch.hub.load('yolov5', 'custom', path='best.pt', source='local')\n",
    "from tqdm import tqdm\n",
    "\n",
    "tqdm.pandas()\n",
    "df = pd.read_csv('../data/dataset.csv')\n",
    "\n",
    "df_pred = df.progress_apply(lambda row: predict_img(row[\"file\"], model), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "048571f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = torch.hub.load('yolov5', 'custom', path='best.pt', source='local')\n",
    "# df = pd.read_csv('../data/dataset.csv')\n",
    "\n",
    "# path = \"\"\n",
    "# predict_img(path, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6559d677",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, mean_absolute_error\n",
    "import ace_tools as tools\n",
    "\n",
    "assert df.shape[0] == df_pred.shape[0]\n",
    "classification_metrics = {}\n",
    "for col in ['mode', 'blocked']:\n",
    "    y_true = df[col].dropna()\n",
    "    y_pred = df_pred.loc[y_true.index, col].dropna()\n",
    "    valid_idx = y_true.index.intersection(y_pred.index)\n",
    "    classification_metrics[col] = {\n",
    "        'accuracy': accuracy_score(df.loc[valid_idx, col], df_pred.loc[valid_idx, col]),\n",
    "        'precision': precision_score(df.loc[valid_idx, col], df_pred.loc[valid_idx, col], zero_division=0),\n",
    "        'recall': recall_score(df.loc[valid_idx, col], df_pred.loc[valid_idx, col], zero_division=0),\n",
    "        'f1': f1_score(df.loc[valid_idx, col], df_pred.loc[valid_idx, col], zero_division=0),\n",
    "        'confusion_matrix': confusion_matrix(df.loc[valid_idx, col], df_pred.loc[valid_idx, col])\n",
    "    }\n",
    "\n",
    "# MAE per a valors continus\n",
    "mae_metrics = {}\n",
    "for col in ['x', 'y', 'theta_rad', 'theta_deg']:\n",
    "    y_true = df[col]\n",
    "    y_pred = df_pred[col]\n",
    "    valid = ~(y_true.isna() | y_pred.isna())\n",
    "    mae_metrics[col] = mean_absolute_error(y_true[valid], y_pred[valid]) if valid.any() else np.nan\n",
    "\n",
    "# Convertim a DataFrame per visualitzar\n",
    "summary_classification = pd.DataFrame({\n",
    "    metric: {\n",
    "        col: val[metric] for col, val in classification_metrics.items()\n",
    "    } for metric in ['accuracy', 'precision', 'recall', 'f1']\n",
    "})\n",
    "\n",
    "summary_mae = pd.Series(mae_metrics, name='MAE').to_frame()\n",
    "\n",
    "tools.display_dataframe_to_user(name=\"Classification Metrics\", dataframe=summary_classification)\n",
    "tools.display_dataframe_to_user(name=\"MAE Metrics\", dataframe=summary_mae)\n",
    "\n",
    "# Dibuixem les matrius de confusió\n",
    "for col in ['mode', 'blocked']:\n",
    "    cm = classification_metrics[col]['confusion_matrix']\n",
    "    plt.figure()\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.title(f'Confusion Matrix - {col}')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
